#PYTHON SCRIPT - TW object recognition URL + ResNet
import torch
import torchvision
import requests
import gc
from torchvision.models.detection import FasterRCNN
from torchvision.transforms import functional as F
from transformers import YolosFeatureExtractor, YolosForObjectDetection, AutoImageProcessor
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
from transformers import pipeline
import os
import tqdm
import pandas as pd
from transformers import AutoImageProcessor, ResNetForImageClassification

# Read the CSV file with image URLs
csv_file = "C:/Users/luigi/OneDrive - University of Glasgow/Desktop/Preliminary Script/twiit&URL for colab.csv"
df = pd.read_csv(csv_file)
#df = df.head(3)
# Create a list to store the results
results = []
long_format_results = []

# Load the pre-trained Faster R-CNN model
model_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model_rcnn.eval()

# Get the COCO label names
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',
    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',
    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# Load the YOLOS model for object detection
feature_extractor_yolos = YolosFeatureExtractor.from_pretrained('hustvl/yolos-base')
model_yolos = YolosForObjectDetection.from_pretrained('hustvl/yolos-base')
image_processor_yolos = AutoImageProcessor.from_pretrained("hustvl/yolos-base")

# Load the BLIP model for image captioning
processor_blip = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model_blip = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Load the image-to-text model
image_to_text = pipeline("image-to-text", model="nlpconnect/vit-gpt2-image-captioning")

# Load the ResNet-50 model for image classification
classification_processor = AutoImageProcessor.from_pretrained("microsoft/resnet-50")
classification_model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")

# Process each image URL
for image_url in tqdm.tqdm(df["x"]):
    try:
        # Download and open the image
        response = requests.get(image_url, stream=True)
        response.raise_for_status()
        image = Image.open(response.raw)

        # Convert image to tensor
        image_tensor = F.to_tensor(image)

        # Perform object detection using Faster R-CNN
        with torch.no_grad():
            predictions = model_rcnn([image_tensor])
        labels = predictions[0]['labels'].tolist()
        boxes = predictions[0]['boxes'].tolist()
        scores = predictions[0]['scores'].tolist()

        # Retrieve label names for Faster R-CNN
        filtered_labels = [COCO_INSTANCE_CATEGORY_NAMES[label] for label in labels]

        # Perform object detection using YOLOS
        inputs_yolos = feature_extractor_yolos(images=image, return_tensors="pt")
        outputs_yolos = model_yolos(**inputs_yolos)
        del inputs_yolos
        target_sizes = torch.tensor([image.size[::-1]])
        yolos_results = image_processor_yolos.post_process(outputs_yolos, target_sizes=target_sizes)[0]
        yolos_labels = [model_yolos.config.id2label[label.item()] for label in yolos_results["labels"]]
        yolos_scores = yolos_results["scores"].tolist()
        yolos_boxes = yolos_results["boxes"].tolist()

        # Perform image captioning using BLIP
        raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')
        inputs_blip = processor_blip(raw_image, return_tensors="pt")
        outputs_blip = model_blip.generate(**inputs_blip)
        caption_blip = processor_blip.decode(outputs_blip[0], skip_special_tokens=True)

        # Perform image-to-text using the Vit-GPT2 model
        text = image_to_text(image)[0]['generated_text']

        # Image classification with ResNet-50
        inputs_classification = classification_processor(image, return_tensors="pt")
        outputs_classification = classification_model(**inputs_classification)
        predicted_label_idx = outputs_classification.logits.argmax(dim=1).item()
        predicted_scores = outputs_classification.logits.softmax(dim=1)[0].tolist()

        logits = outputs_classification.logits
        
        predicted_label = logits.argmax(-1).item()

        # Store the results
        results.append({
            "Image_URL": image_url,
            "FasterRCNN_Labels": filtered_labels,
            "FasterRCNN_Boxes": boxes,
            "FasterRCNN_Scores": scores,
            "YOLOS_Labels": yolos_labels,
            "YOLOS_Boxes": yolos_boxes,
            "YOLOS_Scores": yolos_scores,
            "Caption_blip": caption_blip,
            "Text_gpt2": text,
            "ResNet50_Label": classification_model.config.id2label[predicted_label],
            "ResNet50_Scores": predicted_scores[predicted_label]
        })

        # Append the Faster R-CNN results to the long format
        for label, box, score in zip(filtered_labels, boxes, scores):
            long_format_results.append({
                "image_path": image_url,
                "label": label,
                "box": box,
                "score": score,
                "method": "FasterRCNN"
            })

        # Append the YOLOS results to the long format
        for label, box, score in zip(yolos_labels, yolos_boxes, yolos_scores):
            long_format_results.append({
                "image_path": image_url,
                "label": label,
                "box": box,
                "score": score,
                "method": "YOLOS"
            })

        # Append the caption and text results to the long format
        long_format_results.append({
            "image_path": image_url,
            "label": None,
            "box": None,
            "score": None,
            "method": "Caption_blip",
            "text": caption_blip
        })

        long_format_results.append({
            "image_path": image_url,
            "label": None,
            "box": None,
            "score": None,
            "method": "Text_gpt2",
            "text": text
        })

        # Append the ResNet-50 classification results to the long format
        #long_format_results.append(
        resnet={
            "image_path": image_url,
            "label":classification_model.config.id2label[predicted_label],
            "score":predicted_scores[predicted_label],
            "method":"ResNet50"
        }
        long_format_results.append(resnet)
        print(resnet)
        # Free up memory
        del image, image_tensor, predictions, filtered_labels, boxes, scores
        del outputs_yolos, target_sizes, yolos_results, yolos_labels, yolos_scores, yolos_boxes
        del raw_image, inputs_blip, outputs_blip, caption_blip, text
        gc.collect()

    except Exception as e:
        print(f"Error processing image {image_url}: {str(e)}")

# Convert the results to a DataFrame
results_df = pd.DataFrame(results)

# Save the results to a CSV file
#results_df.to_csv("/content/drive/MyDrive/Colab Notebooks/object_detection_results.csv", index=False)

# Convert the long format results to a DataFrame
long_format_results_df = pd.DataFrame(long_format_results)

# Save the long format results to a CSV file
long_format_results_df.to_csv("C:/Users/luigi/OneDrive - University of Glasgow/Desktop/Preliminary Script/TW_object_detection_results_long_format.csv", index=False)
